{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d610871d-5aa7-409c-a3d7-09bd84b03e39",
   "metadata": {},
   "source": [
    "# Video Classification based on trasncripts\n",
    "\n",
    "A set of *.csv* files conataining the captions from videos is processed to clasify the content using different dictionaries as reference.\n",
    "\n",
    "Each video is tagged with the original search term that recommended it and the depth at which it was recommended to the user. This information is used to present the results graphically. \n",
    "\n",
    "The following dictionaries are used:\n",
    "\n",
    "- **2015 Lexicoder Sentiment Dictionary:** classifies sentiment into positive/negative\n",
    "- **Laver & Garry Dictionary of Policy Position:** classifies topic into CULTURE, ECONOMY, ENVIRONMENT, GROUPS, INSTITUTIONS, LAW_AND_ORDER, RURAL, URBAN, VALUES\n",
    "- **NRC Emotion Lexicon (version 0.92):** classifies emotion into anger, anticipation, disgust, fear, joy, sadness, surprise, and trust\n",
    "- **NRC Emotion Intensity Lexicon (version 1):** classifies emotion into anger, anticipation, disgust, fear, joy, sadness, surprise, and trust and indicates its intensity in a scale of 0 to 1\n",
    "- **NRC Word-Emotion Association Lexicon (NRC Emotion Lexicon):** classifies emotion into anger, fear, anticipation, trust, surprise, sadness, joy, and disgust\n",
    "- **NRC Valence, Arousal, and Dominance (VAD) Lexicon:** indicates the scale from 0 to 1 of valence, arousal and dominance\n",
    "- **AFINN:** measures sentiment from negative to positive in a scale from -5 to 5\n",
    "\n",
    "Young, L. & Soroka, S. (2012). Affective News: The Automated Coding of Sentiment in Political Texts]. doi: 10.1080/10584609.2012.671234. Political Communication, 29(2), 205â€“231.\n",
    "\n",
    "Laver. M. & Garry, J. (2000). Estimating Policy Positions from Political Texts. American Journal of Political Science, 44 (3), 619-634.\n",
    "\n",
    "Word Affect Intensities. Saif M. Mohammad. In Proceedings of the 11th Edition of the\n",
    "Language Resources and Evaluation Conference (LREC-2018), May 2018, Miyazaki, Japan.\n",
    "\n",
    "Saif Mohammad and Peter Turney. Crowdsourcing a Word-Emotion Association Lexicon. Computational Intelligence, 29(3): 436-465, 2013. Wiley Blackwell Publishing Ltd.\n",
    "\n",
    "Saif Mohammad and Peter Turney. Emotions Evoked by Common Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon. In Proceedings of the NAACL-HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, June 2010, LA, California.\n",
    "\n",
    "Obtaining Reliable Human Ratings of Valence, Arousal, and Dominance for 20,000 English Words.\n",
    "Saif M. Mohammad. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Melbourne, Australia, July 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915af146-8a27-4ca6-aeda-b141ac68e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(quanteda)\n",
    "library(seededlda)\n",
    "library(quanteda.corpora)\n",
    "library(gridExtra)\n",
    "library(cowplot)\n",
    "library(numbers)\n",
    "library(ggplot2)\n",
    "library(lingmatch)\n",
    "library(SentimentAnalysis)\n",
    "library(tidyverse)\n",
    "library(tibble)\n",
    "library(\"quanteda.dictionaries\")\n",
    "require(quanteda.textmodels)\n",
    "require(quanteda.textplots)\n",
    "library(quanteda.textstats)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b362d5-0f2d-4de9-b373-a1720c4cc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorizeSubtitles <- function(file) {\n",
    "    data_subs <- read.csv(file)\n",
    "    data_subs<-data_subs[data_subs$subtitles != '',]\n",
    "    data_subs<-data_subs[data_subs$current_depth < 6,]\n",
    "    print(file)\n",
    "    print(paste(\"No. of rows\", nrow(data_subs)))\n",
    "    print(unique(data_subs[c(\"keyword\")]))\n",
    "    corp_subs <- corpus(data_subs, text_field = \"subtitles\")\n",
    "    toks_subs <- tokens(corp_subs, remove_punct = TRUE, remove_numbers = TRUE, remove_symbol = TRUE)\n",
    "    toks_subs <- tokens_remove(toks_subs, pattern = c(stopwords(\"en\")))\n",
    "    \n",
    "    # Positive/Negative 2015 Lexicoder Sentiment Dictionary\n",
    "    \n",
    "    data_dictionary_LSD2015_pos_neg <- data_dictionary_LSD2015[1:2]\n",
    "    toks_subs_lsd <- tokens_lookup(toks_subs, dictionary = data_dictionary_LSD2015_pos_neg)\n",
    "    dfmat_subs_lsd <- dfm(toks_subs_lsd) %>% \n",
    "        dfm_group(groups = current_depth)\n",
    "    dfm_subs <- dfm(toks_subs)\n",
    "    dfm_subs_lsd <- dfm_lookup(dfm_subs, dictionary = data_dictionary_LSD2015_pos_neg)\n",
    "    df_dfm_subs_lsd <- convert(dfm_subs_lsd, to=\"data.frame\")\n",
    "    df_dfm_subs <- docvars(dfm_subs)\n",
    "    \n",
    "    df_pos <- convert(dfmat_subs_lsd, to=\"data.frame\")\n",
    "    df_pos$sentiment <- \"positive\"\n",
    "    df_pos$current_depth <- as.integer(df_pos$doc_id)\n",
    "    df_pos$count <- df_pos$positive\n",
    "    df_pos <- subset(df_pos, select = -c(doc_id, negative, positive))\n",
    "    df_neg <- convert(dfmat_subs_lsd, to=\"data.frame\")\n",
    "    df_neg$sentiment <- \"negative\"\n",
    "    df_neg$current_depth <- as.integer(df_neg$doc_id)\n",
    "    df_neg$count <- df_neg$negative\n",
    "    df_neg <- subset(df_neg, select = -c(doc_id, negative, positive))\n",
    "    df_pos_neg <- rbind(df_pos, df_neg)\n",
    "    \n",
    "    df_net<-convert(dfmat_subs_lsd, to=\"data.frame\")\n",
    "    df_net$current_depth<-as.integer(df_net$doc_id)\n",
    "    df_net$net<-df_net$positive-df_net$negative\n",
    "    df_net<-subset(df_net, select = -c(doc_id, negative, positive))\n",
    "    \n",
    "    df_dfm_subs$positive<-df_dfm_subs_lsd$positive\n",
    "    df_dfm_subs$negative<-df_dfm_subs_lsd$negative\n",
    "    df_dfm_subs$sentiment<-\"positive\"\n",
    "    df_dfm_subs$sentiment[df_dfm_subs$negative>df_dfm_subs$positive]<-\"negative\"\n",
    "    df_dfm_subs$sentiment_ratio<-ifelse(!df_dfm_subs$negative | !df_dfm_subs$positive, 0, df_dfm_subs$positive/df_dfm_subs$negative)\n",
    "    \n",
    "    # Laver & Garry Dictionary of Policy Position\n",
    "    \n",
    "    dfm_subs_lg <- dfm(toks_subs) %>% \n",
    "              dfm_trim(min_termfreq = 0.8, termfreq_type = \"quantile\",\n",
    "                       max_docfreq = 0.1, docfreq_type = \"prop\")\n",
    "    \n",
    "    dict_topic_lg <- dictionary(file = \"Dictionaries/LaverGarry.cat\")\n",
    "    \n",
    "    tmod_slda_lg <- textmodel_seededlda(dfm_subs_lg, dictionary = dict_topic_lg)\n",
    "    \n",
    "    dfm_subs_lg$lgpp <- topics(tmod_slda_lg)\n",
    "    \n",
    "    lg_table<-aggregate(rep(1, nrow(dfm_subs_lg)), by = list(lg_topic = dfm_subs_lg$lgpp, current_depth = dfm_subs_lg$current_depth), sum)\n",
    "    \n",
    "    lg_table$order<-order(lg_table$current_depth, lg_table$x)\n",
    "    \n",
    "    lg_table_0<-lg_table[lg_table$current_depth==0,]\n",
    "    lg_table_1<-lg_table[lg_table$current_depth==1,]\n",
    "    lg_table_2<-lg_table[lg_table$current_depth==2,]\n",
    "    lg_table_3<-lg_table[lg_table$current_depth==3,]\n",
    "    lg_table_4<-lg_table[lg_table$current_depth==4,]\n",
    "    lg_table_5<-lg_table[lg_table$current_depth==5,]\n",
    "    \n",
    "    lg_table_0<-arrange(lg_table_0, lg_table_0$x)\n",
    "    lg_table_1<-arrange(lg_table_1, lg_table_1$x)\n",
    "    lg_table_2<-arrange(lg_table_2, lg_table_2$x)\n",
    "    lg_table_3<-arrange(lg_table_3, lg_table_3$x)\n",
    "    lg_table_4<-arrange(lg_table_4, lg_table_4$x)\n",
    "    lg_table_5<-arrange(lg_table_5, lg_table_5$x)\n",
    "    \n",
    "    lg_table_0$order<-order(lg_table_0$x)\n",
    "    lg_table_1$order<-order(lg_table_1$x)\n",
    "    lg_table_2$order<-order(lg_table_2$x)\n",
    "    lg_table_3$order<-order(lg_table_3$x)\n",
    "    lg_table_4$order<-order(lg_table_4$x)\n",
    "    lg_table_5$order<-order(lg_table_5$x)\n",
    "    \n",
    "    lg_table<- rbind(lg_table_0, lg_table_1, lg_table_2, lg_table_3, lg_table_4, lg_table_5)\n",
    "    \n",
    "    df_dfm_subs$lgpp<-dfm_subs_lg$lgpp\n",
    "    \n",
    "    # NRC Emotion Lexicon (version 0.92)\n",
    "    \n",
    "    dfm_subs_nrc_el <- dfm(toks_subs) %>% \n",
    "              dfm_trim(min_termfreq = 0.8, termfreq_type = \"quantile\",\n",
    "                       max_docfreq = 0.1, docfreq_type = \"prop\")\n",
    "    \n",
    "    tmod_slda_nrc_el <- textmodel_seededlda(dfm_subs_nrc_el, dictionary = data_dictionary_NRC)\n",
    "    \n",
    "    dfm_subs_nrc_el$emotion <- topics(tmod_slda_nrc_el)\n",
    "    \n",
    "    nrc_el_table<-aggregate(rep(1, nrow(dfm_subs_nrc_el)), by = list(emotion = dfm_subs_nrc_el$emotion, current_depth = dfm_subs_nrc_el$current_depth), sum)\n",
    "\n",
    "    nrc_el_table$order<-order(nrc_el_table$current_depth, nrc_el_table$x)\n",
    "    \n",
    "    nrc_el_table_0<-nrc_el_table[nrc_el_table$current_depth==0,]\n",
    "    nrc_el_table_1<-nrc_el_table[nrc_el_table$current_depth==1,]\n",
    "    nrc_el_table_2<-nrc_el_table[nrc_el_table$current_depth==2,]\n",
    "    nrc_el_table_3<-nrc_el_table[nrc_el_table$current_depth==3,]\n",
    "    nrc_el_table_4<-nrc_el_table[nrc_el_table$current_depth==4,]\n",
    "    nrc_el_table_5<-nrc_el_table[nrc_el_table$current_depth==5,]\n",
    "    \n",
    "    nrc_el_table_0<-arrange(nrc_el_table_0, nrc_el_table_0$x)\n",
    "    nrc_el_table_1<-arrange(nrc_el_table_1, nrc_el_table_1$x)\n",
    "    nrc_el_table_2<-arrange(nrc_el_table_2, nrc_el_table_2$x)\n",
    "    nrc_el_table_3<-arrange(nrc_el_table_3, nrc_el_table_3$x)\n",
    "    nrc_el_table_4<-arrange(nrc_el_table_4, nrc_el_table_4$x)\n",
    "    nrc_el_table_5<-arrange(nrc_el_table_5, nrc_el_table_5$x)\n",
    "    \n",
    "    nrc_el_table_0$order<-order(nrc_el_table_0$x)\n",
    "    nrc_el_table_1$order<-order(nrc_el_table_1$x)\n",
    "    nrc_el_table_2$order<-order(nrc_el_table_2$x)\n",
    "    nrc_el_table_3$order<-order(nrc_el_table_3$x)\n",
    "    nrc_el_table_4$order<-order(nrc_el_table_4$x)\n",
    "    nrc_el_table_5$order<-order(nrc_el_table_5$x)\n",
    "    \n",
    "    nrc_el_table<- rbind(nrc_el_table_0, nrc_el_table_1, nrc_el_table_2, nrc_el_table_3, nrc_el_table_4, nrc_el_table_5)\n",
    "\n",
    "    df_dfm_subs$nrc_el<-dfm_subs_nrc_el$emotion\n",
    "    \n",
    "    # topics.yml\n",
    "    \n",
    "    dict_topic <- dictionary(file = \"Dictionaries/topics.yml\")\n",
    "    \n",
    "    dfm_subs_topic <- dfm(toks_subs) %>% \n",
    "              dfm_trim(min_termfreq = 0.8, termfreq_type = \"quantile\",\n",
    "                       max_docfreq = 0.1, docfreq_type = \"prop\")\n",
    "    \n",
    "    tmod_slda_topic <- textmodel_seededlda(dfm_subs_topic, dictionary = dict_topic)\n",
    "    \n",
    "    dfm_subs_topic$topic <- topics(tmod_slda_topic)\n",
    "\n",
    "    topic_table<-aggregate(rep(1, nrow(dfm_subs_topic)), by = list(topic = dfm_subs_topic$topic, current_depth = dfm_subs_topic$current_depth), sum)\n",
    "    \n",
    "    topic_table<-topic_table[order(topic_table$current_depth, topic_table$x),]\n",
    "    \n",
    "    topic_table_0<-topic_table[topic_table$current_depth==0,]\n",
    "    topic_table_1<-topic_table[topic_table$current_depth==1,]\n",
    "    topic_table_2<-topic_table[topic_table$current_depth==2,]\n",
    "    topic_table_3<-topic_table[topic_table$current_depth==3,]\n",
    "    topic_table_4<-topic_table[topic_table$current_depth==4,]\n",
    "    topic_table_5<-topic_table[topic_table$current_depth==5,]\n",
    "    \n",
    "    topic_table_0<-arrange(topic_table_0, topic_table_0$x)\n",
    "    topic_table_1<-arrange(topic_table_1, topic_table_1$x)\n",
    "    topic_table_2<-arrange(topic_table_2, topic_table_2$x)\n",
    "    topic_table_3<-arrange(topic_table_3, topic_table_3$x)\n",
    "    topic_table_4<-arrange(topic_table_4, topic_table_4$x)\n",
    "    topic_table_5<-arrange(topic_table_5, topic_table_5$x)\n",
    "\n",
    "    topic_table_0$order<-order(topic_table_0$x)\n",
    "    topic_table_1$order<-order(topic_table_1$x)\n",
    "    topic_table_2$order<-order(topic_table_2$x)\n",
    "    topic_table_3$order<-order(topic_table_3$x)\n",
    "    topic_table_4$order<-order(topic_table_4$x)\n",
    "    topic_table_5$order<-order(topic_table_5$x)\n",
    "    \n",
    "    topic_table <- rbind(topic_table_0, topic_table_1, topic_table_2, topic_table_3, topic_table_4, topic_table_5)\n",
    "\n",
    "    df_dfm_subs$topic<-dfm_subs_topic$topic\n",
    "    \n",
    "    ## Readability\n",
    "    \n",
    "    docid <- corp_subs$video\n",
    "    docnames(corp_subs) <- docid\n",
    "\n",
    "    ts <- textstat_readability(corp_subs, measure = c('Flesch', 'ARI', 'Flesch.Kincaid'))\n",
    "    \n",
    "    df_ts <-data.frame(ts)\n",
    "    \n",
    "    df_dfm_subs$Flesch<-df_ts$Flesch\n",
    "    df_dfm_subs$ARI<-df_ts$ARI\n",
    "    df_dfm_subs$Flesch.Kincaid<-df_ts$Flesch.Kincaid\n",
    "    \n",
    "    date = format(Sys.time(), \"%Y-%m-%d_%H_%M_%S\")\n",
    "    file_name = paste('Subtitles/Classified/classified_subtitles_',date, '.csv', sep='')\n",
    "    write.csv(df_dfm_subs, file_name)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfccf41-1108-4625-a07e-30c10cce49b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Subtitles/GMCLnb4J-B4.csv\"\n",
      "[1] \"Subtitles/GMCLnb4J-B4.csv\"\n",
      "[1] \"No. of rows 0\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': undefined columns selected\n",
     "output_type": "error",
     "traceback": [
      "Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': undefined columns selected\nTraceback:\n",
      "1. categorizeSubtitles(file)",
      "2. print(unique(data_subs[c(\"keyword\")]))   # at line 7 of file <text>",
      "3. unique(data_subs[c(\"keyword\")])   # at line 7 of file <text>",
      "4. data_subs[c(\"keyword\")]   # at line 7 of file <text>",
      "5. `[.data.frame`(data_subs, c(\"keyword\"))   # at line 7 of file <text>",
      "6. stop(\"undefined columns selected\")",
      "7. .handleSimpleError(function (cond) \n . .Internal(C_tryCatchHelper(addr, 1L, cond)), \"undefined columns selected\", \n .     base::quote(`[.data.frame`(data_subs, c(\"keyword\"))))",
      "8. h(simpleError(msg, call))"
     ]
    }
   ],
   "source": [
    "#file_names <- dir(\"Subtitles/\", pattern = \"subtitles_\")\n",
    "file_names <- dir(\"Subtitles/\", pattern = \".csv\")\n",
    "file_names<-gsub(\" \", \"\", paste(\"Subtitles/\",file_names))\n",
    "\n",
    "for (file in file_names) {\n",
    "    print(file)\n",
    "    categorizeSubtitles(file)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
